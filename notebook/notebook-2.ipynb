{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project overview\n",
    "*   Feature selection   \n",
    "*   Feature extraction  \n",
    "*   Building ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boruta feature selection\n",
    "# PCA, tSNE, UMAP\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from boruta import BorutaPy\n",
    "\n",
    "def feature_selection(path: str = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    X_train=df.drop('Class',axis=1)\n",
    "    y_train= df.Class\n",
    "    # X = df.iloc[:, :-1]\n",
    "    # y = df.iloc[:, -1]\n",
    "    # X = df\n",
    "    # y = df.pop(\"Class\")\n",
    "    estimator = RandomForestClassifier()\n",
    "    # Creates the BorutaPy object\n",
    "    boruta = BorutaPy(estimator = estimator, n_estimators = 'auto', max_iter = 100)\n",
    "    # Fits Boruta\n",
    "    boruta.fit(np.array(X_train), np.array(y_train))\n",
    "    # Important features\n",
    "    important = list(X_train.columns[boruta.support_])\n",
    "    print(f\"Features confirmed as important: {important}\")\n",
    "    # Tentative features\n",
    "    tentative = list(X_train.columns[boruta.support_weak_])\n",
    "    print(f\"Unconfirmed features (tentative): {tentative}\")\n",
    "    # Unimportant features\n",
    "    unimportant = list(X_train.columns[~(boruta.support_ | boruta.support_weak_)])\n",
    "    print(f\"Features confirmed as unimportant: {unimportant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTDATA=\"/home/miki/Desktop/Docker/iNeuron/mice-protien-expression/data/final/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features confirmed as important: ['Unnamed: 0', 'DYRK1A_N', 'ITSN1_N', 'BDNF_N', 'NR1_N', 'NR2A_N', 'pAKT_N', 'pBRAF_N', 'pCAMKII_N', 'pCREB_N', 'pELK_N', 'pERK_N', 'pJNK_N', 'PKCA_N', 'pMEK_N', 'pNR1_N', 'pNR2A_N', 'pNR2B_N', 'pPKCAB_N', 'pRSK_N', 'AKT_N', 'BRAF_N', 'CAMKII_N', 'CREB_N', 'ELK_N', 'ERK_N', 'GSK3B_N', 'JNK_N', 'MEK_N', 'TRKA_N', 'RSK_N', 'APP_N', 'Bcatenin_N', 'SOD1_N', 'MTOR_N', 'P38_N', 'pMTOR_N', 'DSCR1_N', 'AMPKA_N', 'NR2B_N', 'pNUMB_N', 'RAPTOR_N', 'TIAM1_N', 'pP70S6_N', 'NUMB_N', 'P70S6_N', 'pGSK3B_N', 'pPKCG_N', 'CDK5_N', 'S6_N', 'ADARB1_N', 'AcetylH3K9_N', 'RRP1_N', 'BAX_N', 'ARC_N', 'ERBB4_N', 'nNOS_N', 'Tau_N', 'GFAP_N', 'GluR3_N', 'GluR4_N', 'IL1B_N', 'P3525_N', 'pCASP9_N', 'PSD95_N', 'SNCA_N', 'Ubiquitin_N', 'pGSK3B_Tyr216_N', 'SHH_N', 'BAD_N', 'BCL2_N', 'pS6_N', 'pCFOS_N', 'SYP_N', 'H3AcK18_N', 'EGR1_N', 'H3MeK4_N', 'CaNA_N']\n",
      "Unconfirmed features (tentative): []\n",
      "Features confirmed as unimportant: []\n"
     ]
    }
   ],
   "source": [
    "feature_selection(INPUTDATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data():\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_dimensions(): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1885169875.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def tsNE():\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uMAP():\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class DimensionReduction(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def encoder(self):\n",
    "        pass \n",
    "    def scale_data():\n",
    "        pass \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('mice': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0149c2853d78ff9e5b8fecd1729d91754b09ad40777e20ee170517411a5f154"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
